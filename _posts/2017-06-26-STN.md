---
layout:   single
title: "Spatial Transformer Networks"
date: 2017-05-26 20:33:00
categories: Paper
tags: CNN
---

与固定和局部的pooling层对比，Spatial transformer network(STN)可以根据输入的不同的对输入进行特定的转换，使得输出更易于被后面的卷积层进行处理。强大的动态处理机制使得网络对于不同的输入有更强的适应性。
[Spatial transformer networks](https://arxiv.org/pdf/1506.02025.pdf)
{% include toc %}

## Abstract (References form the original)
Convolutional neural network defines an exceptionally powerful class of models, but are still limited by the lack of ability to be spatially invariant to the input data in a computationally and parameter efficient manner. In this work, we introduce a new learnable module, the *Spatial Transformer*, which explicitly allow the spatial manipulation of data within the network. This differentiable module can be inserted into existing convolutional architectures, giving neural network the ability to actively spatially transform feature maps, conditional on the feature map itself, without any extra training supervision or modification to the optimization process. We show that the use of spatial transformers results in modules which learn invariance to translation, scale, rotation and more generic wrapping, resulting in state-of-the-art performance on several benchmarks, and for a number of classes of transformations.

## Introduction
近年来，卷积神经网络在多种任务上都取得了state-of-the-art的性能，如分类、定位、语义分割、动作识别以及其他任务。对于一个系统来说，在物体形变或者变色的情况下依然能够分析出图片的特征，这是一种十分重要的性质。如果使用简单的max-pooling，则需要足够深的网络才能达到spatial invariance这个特性，其中中间层的sptial invariance特性也并不强。因此，*Spatial Transformer*模块不同于固定而且局部视野的pooling层，它的动态转换机制能够在空间上转换输入，使得输出更适用于后面网络的使用，简化了输出的表达。值得一提的是，ST模块能够直接接入到现有的神经网络中，能够使用BP来end to end地学习。

ST能够嵌入到CNN中执行多种任务，比如
    1. 图像分类。
    2. 物体定位。
    3. 空间注意力机制。

![](https://raw.githubusercontent.com/JakeRenn/jakerenn.github.io/master/images/post-STN/post-STN1.png){: .align-center}
(a)输入原图 (b)定位并转化区域 (c)ST输出 (d)网络的最终分类

![](https://raw.githubusercontent.com/JakeRenn/jakerenn.github.io/master/images/post-STN/post-STN2.png){: .align-center}
ST模块的结构。输入U输入到localization net中并回归出参数，常规的空间网格G作用于U来生成V，其中使用了取样网格T，结合localization net和sampling mechanism就得到ST模块。



## Spatial Transformer
Spatial Transformer(ST)是一个可微的模块，它直接作用于特征图上，进行空间变换。对于多通道的特征图，ST会对每个通道进行同一样的wrapping。如上图所示，ST由两个部分组成：
1. localization net，以特征图作为输入，前馈传播通过一系列的隐藏层得到空间变换的参数输出，也就是说空间变化的具体形式取决于输入，简单来说就是动态变换机制。
2. 使用空间变换参数来生成一个取样网格（一系列在输入特征图上的点，在这些点上抽样得到输出）。这个功能由网格生成器(grid generator)完成。
3. 最后，特征图和取样网格一起作为输入到取样器(sampler)中，得到从输入网格中的取样结果作为输出。

### Localization net

$$ theta = f_{loc}(U) $$

$$U$$是输入的特征图，$$f_{loc}$$是localization net，$$theta$$是输出的空间变换参数。其中，localization net可以去任何形式，全连接网络或者卷积神经网络等。

## Parameterized sampling grid
输出为$$V$$
规则的网格 $$G = {G_i}$$ of pixel $$G_i = \{x_i^t, y_i^t\}$$

![](https://raw.githubusercontent.com/JakeRenn/jakerenn.github.io/master/images/post-STN/post-STN3.png){: .align-center}
图(a)表示Identity transformation parameter得到的取样结果，图(b)表示通过一个映射变换$$A_{theta}$$affine transformation的到的取样结果

![](https://raw.githubusercontent.com/JakeRenn/jakerenn.github.io/master/images/post-STN/post-STN4.png){: .align-center}
$$(x_i^t, y_i^t)$$是目标坐标，$$(x_i^s, y_i^s)$$是源坐标。$$A_{theta}$$是映射矩阵。源坐标和目标坐标的值范围都是[-1, 1]。

这个变换公式定义了ST拥有剪切，平移，旋转等功能。映射矩阵只需要6个参数，这些参数有localization net输出。映射矩阵有限制版本：
![](https://raw.githubusercontent.com/JakeRenn/jakerenn.github.io/master/images/post-STN/post-STN5.png){: .align-center}

## Differentiable Image Sampling
理论来说，取样可以取任意形式，只需要它可微。

## Spatial Transformer Network
总的来说，结合localization net, grid generator, sampler就得到一个ST。可以在CNN中任意位置以任意数量加入该模块，这样的网络就叫Spatial Transformer Network(STN)。ST也可以做上采样或者下采样的工具，因为输出的大小是自己定义的。
但是，这种网络的缺点是，ST的数量限制的interested objects的数量。


## 总结
神经网络有强大的特征抽象能力，但是缺点很明显，每一层的神经元数是固定的，pooling层的视野域是固定的，如果要用全连接层的话，连输入大小度需要固定的。在深度足够深的网络中，虽然能够取得很好的抽象特征，但是这是以牺牲更多的计算能力为代价。

这篇论文通过设计一个ST模块，用一个小神经网络去学习如果变换特征图，变换后的特征图易于后面的特征提取，也就是消耗额外的小计算量得到更加有意义的输出。

